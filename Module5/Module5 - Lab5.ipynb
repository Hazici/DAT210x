{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module5- Lab5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('ggplot') # Look Pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Convenience Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDecisionBoundary(model, X, y):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    padding = 0.6\n",
    "    resolution = 0.0025\n",
    "    colors = ['royalblue','forestgreen','ghostwhite']\n",
    "\n",
    "    # Calculate the boundaris\n",
    "    x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "    y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= x_range * padding\n",
    "    y_min -= y_range * padding\n",
    "    x_max += x_range * padding\n",
    "    y_max += y_range * padding\n",
    "\n",
    "    # Create a 2D Grid Matrix. The values stored in the matrix\n",
    "    # are the predictions of the class at at said location\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                       np.arange(y_min, y_max, resolution))\n",
    "\n",
    "    # What class does the classifier say?\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour map\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.terrain)\n",
    "\n",
    "    # Plot the test original points as well...\n",
    "    for label in range(len(np.unique(y))):\n",
    "        indices = np.where(y == label)\n",
    "        plt.scatter(X[indices, 0], X[indices, 1], c=colors[label], label=str(label), alpha=0.8)\n",
    "\n",
    "    p = model.get_params()\n",
    "    plt.axis('tight')\n",
    "    plt.title('K = ' + str(p['n_neighbors']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load up the dataset into a variable called `X`. Check `.head` and `dtypes` to make sure you're loading your data properly--don't fail on the 1st step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./Datasets/wheat.data', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>asymmetry</th>\n",
       "      <th>groove</th>\n",
       "      <th>wheat_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  perimeter  compactness  length  width  asymmetry  groove wheat_type\n",
       "id                                                                            \n",
       "0   15.26      14.84       0.8710   5.763  3.312      2.221   5.220       kama\n",
       "1   14.88      14.57       0.8811   5.554  3.333      1.018   4.956       kama\n",
       "2   14.29      14.09       0.9050   5.291  3.337      2.699   4.825       kama\n",
       "3   13.84      13.94       0.8955   5.324  3.379      2.259   4.805       kama\n",
       "4   16.14      14.99       0.9034   5.658  3.562      1.355   5.175       kama"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area           float64\n",
       "perimeter      float64\n",
       "compactness    float64\n",
       "length         float64\n",
       "width          float64\n",
       "asymmetry      float64\n",
       "groove         float64\n",
       "wheat_type      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area           False\n",
       "perimeter      False\n",
       "compactness     True\n",
       "length         False\n",
       "width           True\n",
       "asymmetry      False\n",
       "groove          True\n",
       "wheat_type     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the `wheat_type` series slice out of `X`, and into a series called `y`. Then drop the original `wheat_type` column from the `X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['wheat_type'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['wheat_type'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>asymmetry</th>\n",
       "      <th>groove</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  perimeter  compactness  length  width  asymmetry  groove\n",
       "id                                                                 \n",
       "0   15.26      14.84       0.8710   5.763  3.312      2.221   5.220\n",
       "1   14.88      14.57       0.8811   5.554  3.333      1.018   4.956\n",
       "2   14.29      14.09       0.9050   5.291  3.337      2.699   4.825\n",
       "3   13.84      13.94       0.8955   5.324  3.379      2.259   4.805\n",
       "4   16.14      14.99       0.9034   5.658  3.562      1.355   5.175"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a quick, \"ordinal\" conversion of `y`. In actuality our classification isn't ordinal, but just as an experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y.astype('category'))\n",
    "y = pd.Categorical(y, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Categorical(y).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some basic nan munging. Fill each row's nans with the mean of the feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>asymmetry</th>\n",
       "      <th>groove</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.2210</td>\n",
       "      <td>5.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.0180</td>\n",
       "      <td>4.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.6990</td>\n",
       "      <td>4.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.2590</td>\n",
       "      <td>4.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.3550</td>\n",
       "      <td>5.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.38</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>5.386</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.4620</td>\n",
       "      <td>4.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.69</td>\n",
       "      <td>14.49</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>5.563</td>\n",
       "      <td>3.259</td>\n",
       "      <td>3.5860</td>\n",
       "      <td>5.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.10</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>5.420</td>\n",
       "      <td>3.302</td>\n",
       "      <td>2.7000</td>\n",
       "      <td>5.407529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.63</td>\n",
       "      <td>15.46</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>6.053</td>\n",
       "      <td>3.465</td>\n",
       "      <td>2.0400</td>\n",
       "      <td>5.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.44</td>\n",
       "      <td>15.25</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.884</td>\n",
       "      <td>3.505</td>\n",
       "      <td>1.9690</td>\n",
       "      <td>5.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>5.714</td>\n",
       "      <td>3.242</td>\n",
       "      <td>4.5430</td>\n",
       "      <td>5.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.03</td>\n",
       "      <td>14.16</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>5.438</td>\n",
       "      <td>3.201</td>\n",
       "      <td>1.7170</td>\n",
       "      <td>5.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.89</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.439</td>\n",
       "      <td>3.199</td>\n",
       "      <td>3.9860</td>\n",
       "      <td>4.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.78</td>\n",
       "      <td>14.06</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>5.479</td>\n",
       "      <td>3.156</td>\n",
       "      <td>3.1360</td>\n",
       "      <td>4.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.74</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>5.482</td>\n",
       "      <td>3.114</td>\n",
       "      <td>2.9320</td>\n",
       "      <td>4.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.59</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>5.351</td>\n",
       "      <td>3.333</td>\n",
       "      <td>4.1850</td>\n",
       "      <td>4.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.99</td>\n",
       "      <td>13.83</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>5.119</td>\n",
       "      <td>3.383</td>\n",
       "      <td>5.2340</td>\n",
       "      <td>4.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.69</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>5.527</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1.5990</td>\n",
       "      <td>5.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.70</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>5.205</td>\n",
       "      <td>3.466</td>\n",
       "      <td>1.7670</td>\n",
       "      <td>4.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.72</td>\n",
       "      <td>13.57</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>5.226</td>\n",
       "      <td>3.049</td>\n",
       "      <td>4.1020</td>\n",
       "      <td>4.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.16</td>\n",
       "      <td>14.40</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.129</td>\n",
       "      <td>3.0720</td>\n",
       "      <td>5.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.26</td>\n",
       "      <td>0.8722</td>\n",
       "      <td>5.520</td>\n",
       "      <td>3.168</td>\n",
       "      <td>2.6880</td>\n",
       "      <td>5.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.88</td>\n",
       "      <td>14.90</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>5.618</td>\n",
       "      <td>3.507</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>5.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.08</td>\n",
       "      <td>13.23</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>5.099</td>\n",
       "      <td>2.936</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>4.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15.01</td>\n",
       "      <td>14.76</td>\n",
       "      <td>0.8657</td>\n",
       "      <td>5.789</td>\n",
       "      <td>3.245</td>\n",
       "      <td>1.7910</td>\n",
       "      <td>5.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.19</td>\n",
       "      <td>15.16</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>5.833</td>\n",
       "      <td>3.421</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>5.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.02</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>5.395</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.3730</td>\n",
       "      <td>4.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.74</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>5.395</td>\n",
       "      <td>2.956</td>\n",
       "      <td>2.5040</td>\n",
       "      <td>4.869000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.18</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>5.541</td>\n",
       "      <td>3.221</td>\n",
       "      <td>2.7540</td>\n",
       "      <td>5.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13.45</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>5.516</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.5310</td>\n",
       "      <td>5.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>11.41</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>5.090</td>\n",
       "      <td>2.775</td>\n",
       "      <td>4.9570</td>\n",
       "      <td>4.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>12.46</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.8706</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.017</td>\n",
       "      <td>4.9870</td>\n",
       "      <td>5.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>5.240</td>\n",
       "      <td>2.909</td>\n",
       "      <td>4.8570</td>\n",
       "      <td>5.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>11.65</td>\n",
       "      <td>13.07</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>5.108</td>\n",
       "      <td>2.850</td>\n",
       "      <td>5.2090</td>\n",
       "      <td>5.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>12.89</td>\n",
       "      <td>13.77</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>5.495</td>\n",
       "      <td>3.026</td>\n",
       "      <td>6.1850</td>\n",
       "      <td>5.316000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>11.56</td>\n",
       "      <td>13.31</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>5.363</td>\n",
       "      <td>2.683</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>5.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>11.81</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>5.413</td>\n",
       "      <td>2.716</td>\n",
       "      <td>4.8980</td>\n",
       "      <td>5.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>10.91</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>5.088</td>\n",
       "      <td>2.675</td>\n",
       "      <td>4.1790</td>\n",
       "      <td>4.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2.821</td>\n",
       "      <td>7.5240</td>\n",
       "      <td>4.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>10.59</td>\n",
       "      <td>12.41</td>\n",
       "      <td>0.8648</td>\n",
       "      <td>4.899</td>\n",
       "      <td>2.787</td>\n",
       "      <td>4.9750</td>\n",
       "      <td>4.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10.93</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>5.046</td>\n",
       "      <td>2.717</td>\n",
       "      <td>5.3980</td>\n",
       "      <td>5.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>11.27</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>5.091</td>\n",
       "      <td>2.804</td>\n",
       "      <td>3.9850</td>\n",
       "      <td>5.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>11.87</td>\n",
       "      <td>13.02</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>5.132</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.5970</td>\n",
       "      <td>5.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>10.82</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>5.180</td>\n",
       "      <td>2.630</td>\n",
       "      <td>4.8530</td>\n",
       "      <td>5.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>12.11</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.8639</td>\n",
       "      <td>5.236</td>\n",
       "      <td>2.975</td>\n",
       "      <td>4.1320</td>\n",
       "      <td>5.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>12.80</td>\n",
       "      <td>13.47</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>5.160</td>\n",
       "      <td>3.126</td>\n",
       "      <td>4.8730</td>\n",
       "      <td>4.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>12.79</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>5.224</td>\n",
       "      <td>3.054</td>\n",
       "      <td>5.4830</td>\n",
       "      <td>4.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>13.37</td>\n",
       "      <td>13.78</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>5.320</td>\n",
       "      <td>3.128</td>\n",
       "      <td>4.6700</td>\n",
       "      <td>5.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>12.62</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>5.410</td>\n",
       "      <td>2.911</td>\n",
       "      <td>3.3060</td>\n",
       "      <td>5.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>12.76</td>\n",
       "      <td>13.38</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>5.073</td>\n",
       "      <td>3.155</td>\n",
       "      <td>2.8280</td>\n",
       "      <td>4.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.44</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>5.219</td>\n",
       "      <td>2.989</td>\n",
       "      <td>5.4720</td>\n",
       "      <td>5.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>12.67</td>\n",
       "      <td>13.32</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>4.984</td>\n",
       "      <td>3.135</td>\n",
       "      <td>2.3000</td>\n",
       "      <td>5.407529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11.18</td>\n",
       "      <td>12.72</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>5.009</td>\n",
       "      <td>2.810</td>\n",
       "      <td>4.0510</td>\n",
       "      <td>4.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>12.70</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>5.183</td>\n",
       "      <td>3.091</td>\n",
       "      <td>8.4560</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>12.37</td>\n",
       "      <td>13.47</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>5.204</td>\n",
       "      <td>2.960</td>\n",
       "      <td>3.9190</td>\n",
       "      <td>5.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.6310</td>\n",
       "      <td>4.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.3250</td>\n",
       "      <td>5.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.3150</td>\n",
       "      <td>5.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.5980</td>\n",
       "      <td>5.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.6370</td>\n",
       "      <td>5.063000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  perimeter  compactness  length  width  asymmetry    groove\n",
       "id                                                                    \n",
       "0    15.26      14.84       0.8710   5.763  3.312     2.2210  5.220000\n",
       "1    14.88      14.57       0.8811   5.554  3.333     1.0180  4.956000\n",
       "2    14.29      14.09       0.9050   5.291  3.337     2.6990  4.825000\n",
       "3    13.84      13.94       0.8955   5.324  3.379     2.2590  4.805000\n",
       "4    16.14      14.99       0.9034   5.658  3.562     1.3550  5.175000\n",
       "5    14.38      14.21       0.8951   5.386  3.312     2.4620  4.956000\n",
       "6    14.69      14.49       0.8799   5.563  3.259     3.5860  5.219000\n",
       "7    14.11      14.10       0.8911   5.420  3.302     2.7000  5.407529\n",
       "8    16.63      15.46       0.8747   6.053  3.465     2.0400  5.877000\n",
       "9    16.44      15.25       0.8880   5.884  3.505     1.9690  5.533000\n",
       "10   15.26      14.85       0.8696   5.714  3.242     4.5430  5.314000\n",
       "11   14.03      14.16       0.8796   5.438  3.201     1.7170  5.001000\n",
       "12   13.89      14.02       0.8880   5.439  3.199     3.9860  4.738000\n",
       "13   13.78      14.06       0.8759   5.479  3.156     3.1360  4.872000\n",
       "14   13.74      14.05       0.8744   5.482  3.114     2.9320  4.825000\n",
       "15   14.59      14.28       0.8993   5.351  3.333     4.1850  4.781000\n",
       "16   13.99      13.83       0.9183   5.119  3.383     5.2340  4.781000\n",
       "17   15.69      14.75       0.9058   5.527  3.514     1.5990  5.046000\n",
       "18   14.70      14.21       0.9153   5.205  3.466     1.7670  4.649000\n",
       "19   12.72      13.57       0.8686   5.226  3.049     4.1020  4.914000\n",
       "20   14.16      14.40       0.8584   5.658  3.129     3.0720  5.176000\n",
       "21   14.11      14.26       0.8722   5.520  3.168     2.6880  5.219000\n",
       "22   15.88      14.90       0.8988   5.618  3.507     0.7651  5.091000\n",
       "23   12.08      13.23       0.8664   5.099  2.936     1.4150  4.961000\n",
       "24   15.01      14.76       0.8657   5.789  3.245     1.7910  5.001000\n",
       "25   16.19      15.16       0.8849   5.833  3.421     0.9030  5.307000\n",
       "26   13.02      13.76       0.8641   5.395  3.026     3.3730  4.825000\n",
       "27   12.74      13.67       0.8564   5.395  2.956     2.5040  4.869000\n",
       "28   14.11      14.18       0.8820   5.541  3.221     2.7540  5.038000\n",
       "29   13.45      14.02       0.8604   5.516  3.065     3.5310  5.097000\n",
       "..     ...        ...          ...     ...    ...        ...       ...\n",
       "180  11.41      12.95       0.8560   5.090  2.775     4.9570  4.825000\n",
       "181  12.46      13.41       0.8706   5.236  3.017     4.9870  5.147000\n",
       "182  12.19      13.36       0.8579   5.240  2.909     4.8570  5.158000\n",
       "183  11.65      13.07       0.8575   5.108  2.850     5.2090  5.135000\n",
       "184  12.89      13.77       0.8541   5.495  3.026     6.1850  5.316000\n",
       "185  11.56      13.31       0.8198   5.363  2.683     4.0620  5.182000\n",
       "186  11.81      13.45       0.8198   5.413  2.716     4.8980  5.352000\n",
       "187  10.91      12.80       0.8372   5.088  2.675     4.1790  4.956000\n",
       "188  11.23      12.82       0.8594   5.089  2.821     7.5240  4.957000\n",
       "189  10.59      12.41       0.8648   4.899  2.787     4.9750  4.794000\n",
       "190  10.93      12.80       0.8390   5.046  2.717     5.3980  5.045000\n",
       "191  11.27      12.86       0.8563   5.091  2.804     3.9850  5.001000\n",
       "192  11.87      13.02       0.8795   5.132  2.953     3.5970  5.132000\n",
       "193  10.82      12.83       0.8256   5.180  2.630     4.8530  5.089000\n",
       "194  12.11      13.27       0.8639   5.236  2.975     4.1320  5.012000\n",
       "195  12.80      13.47       0.8860   5.160  3.126     4.8730  4.914000\n",
       "196  12.79      13.53       0.8786   5.224  3.054     5.4830  4.958000\n",
       "197  13.37      13.78       0.8849   5.320  3.128     4.6700  5.091000\n",
       "198  12.62      13.67       0.8481   5.410  2.911     3.3060  5.231000\n",
       "199  12.76      13.38       0.8964   5.073  3.155     2.8280  4.830000\n",
       "200  12.38      13.44       0.8609   5.219  2.989     5.4720  5.045000\n",
       "201  12.67      13.32       0.8977   4.984  3.135     2.3000  5.407529\n",
       "202  11.18      12.72       0.8680   5.009  2.810     4.0510  4.828000\n",
       "203  12.70      13.41       0.8874   5.183  3.091     8.4560  5.000000\n",
       "204  12.37      13.47       0.8567   5.204  2.960     3.9190  5.001000\n",
       "205  12.19      13.20       0.8783   5.137  2.981     3.6310  4.870000\n",
       "206  11.23      12.88       0.8511   5.140  2.795     4.3250  5.003000\n",
       "207  13.20      13.66       0.8883   5.236  3.232     8.3150  5.056000\n",
       "208  11.84      13.21       0.8521   5.175  2.836     3.5980  5.044000\n",
       "209  12.30      13.34       0.8684   5.243  2.974     5.6370  5.063000\n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.fillna(X.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area           False\n",
       "perimeter      False\n",
       "compactness    False\n",
       "length         False\n",
       "width          False\n",
       "asymmetry      False\n",
       "groove         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split `X` into training and testing data sets using `train_test_split()`. Use `0.33` test size, and use `random_state=1`. This is important so that your answers are verifiable. In the real world, you wouldn't specify a random_state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 2, 0, 2, 1, 2, 2, 2,\n",
       "       0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 1, 2, 2, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2,\n",
       "       1, 2, 0, 1, 2, 2, 0, 1, 0, 2, 1, 0, 2, 2, 1, 1, 2, 2, 0, 2, 0, 1, 1,\n",
       "       2, 2, 0, 2, 2, 1, 2, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 0, 2, 2, 1, 1, 2,\n",
       "       1, 1, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       2, 2, 0, 1, 0, 0, 0, 2, 0, 2, 1, 0, 1, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2,\n",
       "       0, 1], dtype=int8)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of SKLearn's Normalizer class and then train it using its .fit() method against your _training_ data. The reason you only fit against your training data is because in a real-world situation, you'll only have your training data to train with! In this lab setting, you have both train+test data; but in the wild, you'll only have your training data, and then unlabeled data you want to apply your models to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "T = preprocessing.Normalizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your trained pre-processor, transform both your training AND testing data. Any testing data has to be transformed with your preprocessor that has ben fit against your training data, so that it exist in the same feature-space as the original data used to train your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = T.transform(X_train)\n",
    "X_test = T.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Just like your preprocessing transformation, create a PCA transformation as well. Fit it against your training data, and then project your training and testing features into PCA space using the PCA model's `.transform()` method. This has to be done because the only way to visualize the decision boundary in 2D would be if your KNN algo ran in 2D as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = PCA(n_components=2)\n",
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = model.transform(X_train)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train a KNeighborsClassifier. Start with `K=9` neighbors. Be sure train your classifier against the pre-processed, PCA- transformed training data above! You do not, of course, need to transform your labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I hope your KNeighbors classifier model from earlier was named 'knn'\n",
    "# If not, adjust the following line:\n",
    "plotDecisionBoundary(knn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the accuracy score of your test data/labels, computed by your KNeighbors model. You do NOT have to run `.predict` before calling `.score`, since `.score` will take care of running your predictions for you automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87142857142857144"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the ordinal conversion, try and get this assignment working with a proper Pandas get_dummies for feature encoding. You might have to update some of the `plotDecisionBoundary()` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEJCAYAAACQZoDoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQkSRwCCEECKKBAYhhBBR/n9m2UOhxDQrEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd24c668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
